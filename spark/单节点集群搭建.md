# 基础环境

## 搭建目标
|序号| 主机名      | 安装软件  | 用户名 |
|--:| --------: | -----:       | -----: |
|1  | master01  | NN/DN/RM/Master/Worker      | hadoop |
|2  | slave01   | DN/NM/Worker | hadoop |
|3  | slave02   | DN/NM/Worker | hadoop |

## 修改主机名
```
vi /etc/hostname
hostname xxx
```

## 配置主机
```
192.168.0.200 master01
192.168.0.201 slave01
192.168.0.202 slave02
```

## 免密登录(root用户和hadoop用户最好都做)
```
cd ~/.ssh/ # 若没有该目录，请先执行一次ssh localhost
ssh-keygen -t rsa # 会有提示，都按回车就可以
ssh-copy-id hostname # 执行完后ssh hostname 登录一次主机
```

## 安装JDK
```
tar -xzf jdk-8u191-linux-x64.tar.gz
export JAVA_HOME=/opt/app/java/jdk1.8.0_191
export PATH=$PATH:$JAVA_HOME/bin
```

## 时间同步
```
apt install -y ntpdate
ntpdate ntp1.aliyun.com
```

## 修改时区（可能的）
```
tzselect
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
```

# Hadoop安装(先在master上配置，然后scp到从机)

## 添加hadoop到环境变量/etc/profile
```
export JAVA_HOME=/opt/app/java/jdk1.8.0_191
export HADOOP_HOME=/opt/app/hadoop/hadoop-2.9.2
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin
```

## 修改hadoop-env.sh中的JAVA_HOME
```
export JAVA_HOME=/opt/app/java/jdk1.8.0_191
```

## 修改slaves文件
```
master01
slave01
slave02
```

## 修改其他配置文件，详见文件夹中内容

## 启动hadoop
```
hdfs namenode -format
start-dfs.sh
start-yarn.sh
```

# 安装Scala

## 配置环境变量
```
tar -xzvf scala-2.13.1.tgz

export JAVA_HOME=/opt/app/java/jdk1.8.0_191
export HADOOP_HOME=/opt/app/hadoop/hadoop-2.9.2
export SPARK_HOME=/opt/app/spark/spark-2.4.4-bin-hadoop2.7
export SCALA_HOME=/opt/app/scala/scala-2.13.1
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$SPARK_HOME/bin
```

# Spark安装

## 添加spark到环境变量/etc/profile
```
export JAVA_HOME=/opt/app/java/jdk1.8.0_191
export HADOOP_HOME=/opt/app/hadoop/hadoop-2.9.2
export SPARK_HOME=/opt/app/spark/spark-2.4.4-bin-hadoop2.7
export SCALA_HOME=/opt/app/scala/scala-2.13.1
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$SPARK_HOME/bin:$SCALA_HOME/bin
```

## 配置slaves文件
```
slave01
slave02
```

## 配置spark-env.sh
```
export JAVA_HOME=/opt/app/java/jdk1.8.0_191
export SCALA_HOME=/opt/app/scala/scala-2.13.1
export HADOOP_HOME=/opt/app/hadoop/hadoop-2.9.2
export HADOOP_CONF_DIR=/opt/app/hadoop/hadoop-2.9.2/etc/hadoop
export SPARK_MASTER_IP=master01
```

